{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ranking-promise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\nfrom IPython.core.display import display, HTML\\n\\ndisplay(HTML(\\\"<style>.container { width:90% !important; }</style>\\\"))\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\nfrom IPython.core.display import display, HTML\\n\\ndisplay(HTML(\\\"<style>.container { width:90% !important; }</style>\\\"))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "opponent-steering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom typing import Tuple, Union, Dict, List\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport numpy as np\\nfrom typing import Tuple, Union, Dict, List\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Tuple, Union, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "single-niger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 69;\n",
       "                var nbb_unformatted_code = \"import matplotlib.pyplot as plt\";\n",
       "                var nbb_formatted_code = \"import matplotlib.pyplot as plt\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "exciting-learning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 102;\n",
       "                var nbb_unformatted_code = \"class DecisionNode:\\n    def __init__(self, question, true_node, false_node):\\n        self.question = question\\n        self.true_node = true_node\\n        self.false_node = false_node\\n\\n\\nclass Leaf:\\n    \\\"\\\"\\\"Just want the class probabilities\\\"\\\"\\\"\\n\\n    def __init__(self, rows):\\n        self.mean = self.find_leaf_mean(rows)\\n\\n    def find_leaf_mean(self, rows: pd.DataFrame) -> Dict:\\n        return np.mean(rows[\\\"label\\\"])\\n\\n    def __repr__(self) -> str:\\n        return str(self.mean)\\n\\n\\nclass Question:\\n    def __init__(self, feature: str, value: Union[str, float, int]):\\n        self.feature = feature\\n        self.value = value\\n        self.is_numeric_feature = self.is_numeric(value)\\n\\n    @staticmethod\\n    def is_numeric(value):\\n        \\\"\\\"\\\"Test if a value is numeric.\\\"\\\"\\\"\\n        return isinstance(value, int) or isinstance(value, float)\\n\\n    def ask(self, rows: pd.DataFrame) -> pd.Series:\\n        if self.is_numeric_feature:\\n            answer = rows[self.feature] >= self.value\\n        else:\\n            answer = rows[self.feature] == self.value\\n\\n        return answer\\n\\n    def __repr__(self) -> str:\\n        if self.is_numeric_feature:\\n            return f\\\"Is {self.feature} >= {self.value}?\\\"\\n        else:\\n            return f\\\"Is {self.feature} == {self.value}?\\\"\\n\\n\\n# At every node I want to find the best question\\nclass RegressionTree:\\n    def __init__(self, features):\\n        self.features = features\\n\\n    @staticmethod\\n    def gini(rows: pd.DataFrame) -> pd.DataFrame:\\n        n = len(rows)\\n        clas_prob = rows.groupby(\\\"label\\\").agg(**{\\\"prob\\\": (\\\"label\\\", \\\"count\\\")}) / n\\n        return 1 - np.sum(clas_prob[\\\"prob\\\"] ** 2)\\n\\n    @staticmethod\\n    def variance(rows: pd.DataFrame) -> pd.DataFrame:\\n        return np.var(rows[\\\"label\\\"])\\n\\n    def weighted_average_gini(self, true_values, false_values):\\n        n_true = len(true_values)\\n        n_false = len(false_values)\\n        n = n_true + n_false\\n        weighted_gini = (n_true / n) * self.gini(true_values) + (\\n            n_false / n\\n        ) * self.gini(false_values)\\n        return weighted_gini\\n\\n    def weighted_average_variance(self, true_values, false_values):\\n        n_true = len(true_values)\\n        n_false = len(false_values)\\n        n = n_true + n_false\\n        weighted_var = (n_true / n) * self.variance(true_values) + (\\n            n_false / n\\n        ) * self.variance(false_values)\\n        return weighted_var\\n\\n    def find_unique_values(self, series: pd.Series) -> List:\\n        return series.drop_duplicates().to_list()\\n\\n    def find_best_question(self, rows: pd.DataFrame) -> Tuple[Question, float]:\\n        # For a data set, what is the bets question I can ask to split the data\\n        # for every feature I want to create a bunch of questions\\n        # I want to find the question which reduces the gini the most\\n        # #\\n        variance_before_split = self.variance(rows)\\n\\n        best_question = None\\n        best_gain = 0\\n\\n        for feat in self.features:\\n            possible_vals = self.find_unique_values(rows[feat])\\n            for val in possible_vals:\\n                q = Question(feature=feat, value=val)\\n                is_cond_true = q.ask(rows=rows)\\n                true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\\n                # get weighted average gini\\n                variance_after_split = self.weighted_average_variance(\\n                    true_rows, false_rows\\n                )\\n                # find the information gain from asking the question\\n                info_gain = variance_before_split - variance_after_split\\n                if (\\n                    (info_gain >= best_gain)\\n                    & (len(true_rows) > 2)\\n                    & (len(false_rows) > 2)\\n                ):\\n                    best_question = q\\n                    best_gain = info_gain\\n\\n        return best_question, best_gain\\n\\n    def split(\\n        self, rows: pd.DataFrame, question: Question\\n    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\\n        \\\"\\\"\\\"Return the data for the left and right nodes \\\"\\\"\\\"\\n\\n        is_cond_true = question.ask(rows=rows)\\n        true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\\n\\n        return true_rows, false_rows\\n\\n    def build_tree(self, rows: pd.DataFrame) -> DecisionNode:\\n        question_, gain_ = self.find_best_question(rows)\\n\\n        if gain_ == 0:\\n            return Leaf(rows=rows)\\n\\n        true_rows, false_rows = self.split(rows=rows, question=question_)\\n\\n        return DecisionNode(\\n            question=question_,\\n            true_node=self.build_tree(true_rows),\\n            false_node=self.build_tree(false_rows),\\n        )\\n\\n    def fit(rows: pd.DataFrame) -> None:\\n        pass\\n\\n\\ndef print_tree(node: Union[DecisionNode, Leaf], level=0) -> None:\\n    prefix = \\\" \\\" * 2 ** level + \\\"|__\\\" if level > 0 else \\\"\\\"\\n\\n    if isinstance(node, Leaf):\\n        print(prefix, node)\\n        return\\n\\n    print(prefix, node.question)\\n\\n    print_tree(node.true_node, level=level + 1)\\n    print_tree(node.false_node, level=level + 1)\\n\\n\\ndef predict(node, row: pd.DataFrame, level=0):\\n    prefix = \\\" \\\" * 2 ** level + \\\"|__\\\" if level > 0 else \\\"\\\"\\n\\n    if isinstance(node, Leaf):\\n        return node.mean\\n    is_cond_true = node.question.ask(row)\\n\\n    if is_cond_true.values[0]:\\n        return predict(node=node.true_node, row=row)\\n    else:\\n        return predict(node=node.false_node, row=row)\";\n",
       "                var nbb_formatted_code = \"class DecisionNode:\\n    def __init__(self, question, true_node, false_node):\\n        self.question = question\\n        self.true_node = true_node\\n        self.false_node = false_node\\n\\n\\nclass Leaf:\\n    \\\"\\\"\\\"Just want the class probabilities\\\"\\\"\\\"\\n\\n    def __init__(self, rows):\\n        self.mean = self.find_leaf_mean(rows)\\n\\n    def find_leaf_mean(self, rows: pd.DataFrame) -> Dict:\\n        return np.mean(rows[\\\"label\\\"])\\n\\n    def __repr__(self) -> str:\\n        return str(self.mean)\\n\\n\\nclass Question:\\n    def __init__(self, feature: str, value: Union[str, float, int]):\\n        self.feature = feature\\n        self.value = value\\n        self.is_numeric_feature = self.is_numeric(value)\\n\\n    @staticmethod\\n    def is_numeric(value):\\n        \\\"\\\"\\\"Test if a value is numeric.\\\"\\\"\\\"\\n        return isinstance(value, int) or isinstance(value, float)\\n\\n    def ask(self, rows: pd.DataFrame) -> pd.Series:\\n        if self.is_numeric_feature:\\n            answer = rows[self.feature] >= self.value\\n        else:\\n            answer = rows[self.feature] == self.value\\n\\n        return answer\\n\\n    def __repr__(self) -> str:\\n        if self.is_numeric_feature:\\n            return f\\\"Is {self.feature} >= {self.value}?\\\"\\n        else:\\n            return f\\\"Is {self.feature} == {self.value}?\\\"\\n\\n\\n# At every node I want to find the best question\\nclass RegressionTree:\\n    def __init__(self, features):\\n        self.features = features\\n\\n    @staticmethod\\n    def gini(rows: pd.DataFrame) -> pd.DataFrame:\\n        n = len(rows)\\n        clas_prob = rows.groupby(\\\"label\\\").agg(**{\\\"prob\\\": (\\\"label\\\", \\\"count\\\")}) / n\\n        return 1 - np.sum(clas_prob[\\\"prob\\\"] ** 2)\\n\\n    @staticmethod\\n    def variance(rows: pd.DataFrame) -> pd.DataFrame:\\n        return np.var(rows[\\\"label\\\"])\\n\\n    def weighted_average_gini(self, true_values, false_values):\\n        n_true = len(true_values)\\n        n_false = len(false_values)\\n        n = n_true + n_false\\n        weighted_gini = (n_true / n) * self.gini(true_values) + (\\n            n_false / n\\n        ) * self.gini(false_values)\\n        return weighted_gini\\n\\n    def weighted_average_variance(self, true_values, false_values):\\n        n_true = len(true_values)\\n        n_false = len(false_values)\\n        n = n_true + n_false\\n        weighted_var = (n_true / n) * self.variance(true_values) + (\\n            n_false / n\\n        ) * self.variance(false_values)\\n        return weighted_var\\n\\n    def find_unique_values(self, series: pd.Series) -> List:\\n        return series.drop_duplicates().to_list()\\n\\n    def find_best_question(self, rows: pd.DataFrame) -> Tuple[Question, float]:\\n        # For a data set, what is the bets question I can ask to split the data\\n        # for every feature I want to create a bunch of questions\\n        # I want to find the question which reduces the gini the most\\n        # #\\n        variance_before_split = self.variance(rows)\\n\\n        best_question = None\\n        best_gain = 0\\n\\n        for feat in self.features:\\n            possible_vals = self.find_unique_values(rows[feat])\\n            for val in possible_vals:\\n                q = Question(feature=feat, value=val)\\n                is_cond_true = q.ask(rows=rows)\\n                true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\\n                # get weighted average gini\\n                variance_after_split = self.weighted_average_variance(\\n                    true_rows, false_rows\\n                )\\n                # find the information gain from asking the question\\n                info_gain = variance_before_split - variance_after_split\\n                if (\\n                    (info_gain >= best_gain)\\n                    & (len(true_rows) > 2)\\n                    & (len(false_rows) > 2)\\n                ):\\n                    best_question = q\\n                    best_gain = info_gain\\n\\n        return best_question, best_gain\\n\\n    def split(\\n        self, rows: pd.DataFrame, question: Question\\n    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\\n        \\\"\\\"\\\"Return the data for the left and right nodes \\\"\\\"\\\"\\n\\n        is_cond_true = question.ask(rows=rows)\\n        true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\\n\\n        return true_rows, false_rows\\n\\n    def build_tree(self, rows: pd.DataFrame) -> DecisionNode:\\n        question_, gain_ = self.find_best_question(rows)\\n\\n        if gain_ == 0:\\n            return Leaf(rows=rows)\\n\\n        true_rows, false_rows = self.split(rows=rows, question=question_)\\n\\n        return DecisionNode(\\n            question=question_,\\n            true_node=self.build_tree(true_rows),\\n            false_node=self.build_tree(false_rows),\\n        )\\n\\n    def fit(rows: pd.DataFrame) -> None:\\n        pass\\n\\n\\ndef print_tree(node: Union[DecisionNode, Leaf], level=0) -> None:\\n    prefix = \\\" \\\" * 2 ** level + \\\"|__\\\" if level > 0 else \\\"\\\"\\n\\n    if isinstance(node, Leaf):\\n        print(prefix, node)\\n        return\\n\\n    print(prefix, node.question)\\n\\n    print_tree(node.true_node, level=level + 1)\\n    print_tree(node.false_node, level=level + 1)\\n\\n\\ndef predict(node, row: pd.DataFrame, level=0):\\n    prefix = \\\" \\\" * 2 ** level + \\\"|__\\\" if level > 0 else \\\"\\\"\\n\\n    if isinstance(node, Leaf):\\n        return node.mean\\n    is_cond_true = node.question.ask(row)\\n\\n    if is_cond_true.values[0]:\\n        return predict(node=node.true_node, row=row)\\n    else:\\n        return predict(node=node.false_node, row=row)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, question, true_node, false_node):\n",
    "        self.question = question\n",
    "        self.true_node = true_node\n",
    "        self.false_node = false_node\n",
    "\n",
    "\n",
    "class Leaf:\n",
    "    \"\"\"Just want the class probabilities\"\"\"\n",
    "\n",
    "    def __init__(self, rows):\n",
    "        self.mean = self.find_leaf_mean(rows)\n",
    "\n",
    "    def find_leaf_mean(self, rows: pd.DataFrame) -> Dict:\n",
    "        return np.mean(rows[\"label\"])\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return str(self.mean)\n",
    "\n",
    "\n",
    "class Question:\n",
    "    def __init__(self, feature: str, value: Union[str, float, int]):\n",
    "        self.feature = feature\n",
    "        self.value = value\n",
    "        self.is_numeric_feature = self.is_numeric(value)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_numeric(value):\n",
    "        \"\"\"Test if a value is numeric.\"\"\"\n",
    "        return isinstance(value, int) or isinstance(value, float)\n",
    "\n",
    "    def ask(self, rows: pd.DataFrame) -> pd.Series:\n",
    "        if self.is_numeric_feature:\n",
    "            answer = rows[self.feature] >= self.value\n",
    "        else:\n",
    "            answer = rows[self.feature] == self.value\n",
    "\n",
    "        return answer\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        if self.is_numeric_feature:\n",
    "            return f\"Is {self.feature} >= {self.value}?\"\n",
    "        else:\n",
    "            return f\"Is {self.feature} == {self.value}?\"\n",
    "\n",
    "\n",
    "# At every node I want to find the best question\n",
    "class RegressionTree:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "\n",
    "    @staticmethod\n",
    "    def gini(rows: pd.DataFrame) -> pd.DataFrame:\n",
    "        n = len(rows)\n",
    "        clas_prob = rows.groupby(\"label\").agg(**{\"prob\": (\"label\", \"count\")}) / n\n",
    "        return 1 - np.sum(clas_prob[\"prob\"] ** 2)\n",
    "\n",
    "    @staticmethod\n",
    "    def variance(rows: pd.DataFrame) -> pd.DataFrame:\n",
    "        return np.var(rows[\"label\"])\n",
    "\n",
    "    def weighted_average_gini(self, true_values, false_values):\n",
    "        n_true = len(true_values)\n",
    "        n_false = len(false_values)\n",
    "        n = n_true + n_false\n",
    "        weighted_gini = (n_true / n) * self.gini(true_values) + (\n",
    "            n_false / n\n",
    "        ) * self.gini(false_values)\n",
    "        return weighted_gini\n",
    "\n",
    "    def weighted_average_variance(self, true_values, false_values):\n",
    "        n_true = len(true_values)\n",
    "        n_false = len(false_values)\n",
    "        n = n_true + n_false\n",
    "        weighted_var = (n_true / n) * self.variance(true_values) + (\n",
    "            n_false / n\n",
    "        ) * self.variance(false_values)\n",
    "        return weighted_var\n",
    "\n",
    "    def find_unique_values(self, series: pd.Series) -> List:\n",
    "        return series.drop_duplicates().to_list()\n",
    "\n",
    "    def find_best_question(self, rows: pd.DataFrame) -> Tuple[Question, float]:\n",
    "        # For a data set, what is the bets question I can ask to split the data\n",
    "        # for every feature I want to create a bunch of questions\n",
    "        # I want to find the question which reduces the gini the most\n",
    "        # #\n",
    "        variance_before_split = self.variance(rows)\n",
    "\n",
    "        best_question = None\n",
    "        best_gain = 0\n",
    "\n",
    "        for feat in self.features:\n",
    "            possible_vals = self.find_unique_values(rows[feat])\n",
    "            for val in possible_vals:\n",
    "                q = Question(feature=feat, value=val)\n",
    "                is_cond_true = q.ask(rows=rows)\n",
    "                true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\n",
    "                # get weighted average gini\n",
    "                variance_after_split = self.weighted_average_variance(\n",
    "                    true_rows, false_rows\n",
    "                )\n",
    "                # find the information gain from asking the question\n",
    "                info_gain = variance_before_split - variance_after_split\n",
    "                if (\n",
    "                    (info_gain >= best_gain)\n",
    "                    & (len(true_rows) > 2)\n",
    "                    & (len(false_rows) > 2)\n",
    "                ):\n",
    "                    best_question = q\n",
    "                    best_gain = info_gain\n",
    "\n",
    "        return best_question, best_gain\n",
    "\n",
    "    def split(\n",
    "        self, rows: pd.DataFrame, question: Question\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"Return the data for the left and right nodes \"\"\"\n",
    "\n",
    "        is_cond_true = question.ask(rows=rows)\n",
    "        true_rows, false_rows = rows[is_cond_true], rows[~is_cond_true]\n",
    "\n",
    "        return true_rows, false_rows\n",
    "\n",
    "    def build_tree(self, rows: pd.DataFrame) -> DecisionNode:\n",
    "        question_, gain_ = self.find_best_question(rows)\n",
    "\n",
    "        if gain_ == 0:\n",
    "            return Leaf(rows=rows)\n",
    "\n",
    "        true_rows, false_rows = self.split(rows=rows, question=question_)\n",
    "\n",
    "        return DecisionNode(\n",
    "            question=question_,\n",
    "            true_node=self.build_tree(true_rows),\n",
    "            false_node=self.build_tree(false_rows),\n",
    "        )\n",
    "\n",
    "    def fit(rows: pd.DataFrame) -> None:\n",
    "        pass\n",
    "\n",
    "\n",
    "def print_tree(node: Union[DecisionNode, Leaf], level=0) -> None:\n",
    "    prefix = \" \" * 2 ** level + \"|__\" if level > 0 else \"\"\n",
    "\n",
    "    if isinstance(node, Leaf):\n",
    "        print(prefix, node)\n",
    "        return\n",
    "\n",
    "    print(prefix, node.question)\n",
    "\n",
    "    print_tree(node.true_node, level=level + 1)\n",
    "    print_tree(node.false_node, level=level + 1)\n",
    "\n",
    "\n",
    "def predict(node, row: pd.DataFrame, level=0):\n",
    "    prefix = \" \" * 2 ** level + \"|__\" if level > 0 else \"\"\n",
    "\n",
    "    if isinstance(node, Leaf):\n",
    "        return node.mean\n",
    "    is_cond_true = node.question.ask(row)\n",
    "\n",
    "    if is_cond_true.values[0]:\n",
    "        return predict(node=node.true_node, row=row)\n",
    "    else:\n",
    "        return predict(node=node.false_node, row=row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "qualified-musical",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-50</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-50</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   color  label\n",
       "0    -50    1.0\n",
       "1     20    2.0\n",
       "2     20    2.5\n",
       "3     20    2.0\n",
       "4    -50    1.5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 63;\n",
       "                var nbb_unformatted_code = \"training_data = pd.DataFrame(\\n    [[-50, 1], [20, 2], [20, 2.5], [20, 2], [-50, 1.5],],\\n    columns=[\\\"color\\\", \\\"label\\\"],\\n)\\n\\ntraining_data\";\n",
       "                var nbb_formatted_code = \"training_data = pd.DataFrame(\\n    [[-50, 1], [20, 2], [20, 2.5], [20, 2], [-50, 1.5],], columns=[\\\"color\\\", \\\"label\\\"],\\n)\\n\\ntraining_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = pd.DataFrame(\n",
    "    [[-50, 1], [20, 2], [20, 2.5], [20, 2], [-50, 1.5],], columns=[\"color\", \"label\"],\n",
    ")\n",
    "\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "confidential-check",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd834d0e950>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 103;\n",
       "                var nbb_unformatted_code = \"training_data = pd.DataFrame(\\n    [\\n        # Regime 1\\n        [0.5, 1],\\n        [2, 2],\\n        [5, 2.5],\\n        [10.5, 4],\\n        [12.5, 3],\\n        # Regime 2\\n        [16, 99.0],\\n        [18, 99.0],\\n        [24, 100.0],\\n        [26.0, 100.0],\\n        # Regime 3\\n        [30, 72.0],\\n        [32, 68.0],\\n        [34, 54],\\n        [36.0, 40.0],\\n        # Regime 4\\n        [40.0, 8.0],\\n        [41.5, 7],\\n        [43, 4],\\n        [45.0, 3.2],\\n    ],\\n    columns=[\\\"dosage\\\", \\\"label\\\"],\\n)\\n\\nplt.scatter(x=training_data[\\\"dosage\\\"], y=training_data[\\\"label\\\"])\";\n",
       "                var nbb_formatted_code = \"training_data = pd.DataFrame(\\n    [\\n        # Regime 1\\n        [0.5, 1],\\n        [2, 2],\\n        [5, 2.5],\\n        [10.5, 4],\\n        [12.5, 3],\\n        # Regime 2\\n        [16, 99.0],\\n        [18, 99.0],\\n        [24, 100.0],\\n        [26.0, 100.0],\\n        # Regime 3\\n        [30, 72.0],\\n        [32, 68.0],\\n        [34, 54],\\n        [36.0, 40.0],\\n        # Regime 4\\n        [40.0, 8.0],\\n        [41.5, 7],\\n        [43, 4],\\n        [45.0, 3.2],\\n    ],\\n    columns=[\\\"dosage\\\", \\\"label\\\"],\\n)\\n\\nplt.scatter(x=training_data[\\\"dosage\\\"], y=training_data[\\\"label\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_data = pd.DataFrame(\n",
    "    [\n",
    "        # Regime 1\n",
    "        [0.5, 1],\n",
    "        [2, 2],\n",
    "        [5, 2.5],\n",
    "        [10.5, 4],\n",
    "        [12.5, 3],\n",
    "        # Regime 2\n",
    "        [16, 99.0],\n",
    "        [18, 99.0],\n",
    "        [24, 100.0],\n",
    "        [26.0, 100.0],\n",
    "        # Regime 3\n",
    "        [30, 72.0],\n",
    "        [32, 68.0],\n",
    "        [34, 54],\n",
    "        [36.0, 40.0],\n",
    "        # Regime 4\n",
    "        [40.0, 8.0],\n",
    "        [41.5, 7],\n",
    "        [43, 4],\n",
    "        [45.0, 3.2],\n",
    "    ],\n",
    "    columns=[\"dosage\", \"label\"],\n",
    ")\n",
    "\n",
    "plt.scatter(x=training_data[\"dosage\"], y=training_data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "substantial-latvia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is dosage >= 16.0?\n",
      "  |__ Is dosage >= 36.0?\n",
      "    |__ 12.440000000000001\n",
      "    |__ Is dosage >= 30.0?\n",
      "        |__ 64.66666666666667\n",
      "        |__ 99.5\n",
      "  |__ 2.5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 104;\n",
       "                var nbb_unformatted_code = \"mod = RegressionTree(features=[\\\"dosage\\\"])\\ntree = mod.build_tree(training_data)\\nprint_tree(tree)\";\n",
       "                var nbb_formatted_code = \"mod = RegressionTree(features=[\\\"dosage\\\"])\\ntree = mod.build_tree(training_data)\\nprint_tree(tree)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = RegressionTree(features=[\"dosage\"])\n",
    "tree = mod.build_tree(training_data)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dietary-personal",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 106;\n",
       "                var nbb_unformatted_code = \"testing_data = pd.DataFrame(np.linspace(start=1, stop=45, num=40), columns=[\\\"dosage\\\"])\";\n",
       "                var nbb_formatted_code = \"testing_data = pd.DataFrame(np.linspace(start=1, stop=45, num=40), columns=[\\\"dosage\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data = pd.DataFrame(np.linspace(start=1, stop=45, num=40), columns=[\"dosage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "honest-movement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 107;\n",
       "                var nbb_unformatted_code = \"preds = []\\nfor i in range(len(testing_data)):\\n    preds.append(predict(tree, testing_data[i : i + 1]))\";\n",
       "                var nbb_formatted_code = \"preds = []\\nfor i in range(len(testing_data)):\\n    preds.append(predict(tree, testing_data[i : i + 1]))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = []\n",
    "for i in range(len(testing_data)):\n",
    "    preds.append(predict(tree, testing_data[i : i + 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "third-scoop",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 108;\n",
       "                var nbb_unformatted_code = \"testing_data = testing_data.assign(**{\\\"pred\\\": preds})\";\n",
       "                var nbb_formatted_code = \"testing_data = testing_data.assign(**{\\\"pred\\\": preds})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "testing_data = testing_data.assign(**{\"pred\": preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "round-magnet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd834f155d0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 109;\n",
       "                var nbb_unformatted_code = \"plt.scatter(x=testing_data[\\\"dosage\\\"], y=testing_data[\\\"pred\\\"])\";\n",
       "                var nbb_formatted_code = \"plt.scatter(x=testing_data[\\\"dosage\\\"], y=testing_data[\\\"pred\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=testing_data[\"dosage\"], y=testing_data[\"pred\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-theology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
